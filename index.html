<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Derolol Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Derolol Blog"><meta name="msapplication-TileImage" content="https://raw.githubusercontent.com/derolol/picgo/main/images/logo.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Derolol Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Derolol Blog"><meta property="og:url" content="https://derolol.github.io/"><meta property="og:site_name" content="Derolol Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://derolol.github.io/img/og_image.png"><meta property="article:author" content="derolol"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://derolol.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://derolol.github.io"},"headline":"Derolol Blog","image":["https://derolol.github.io/img/og_image.png"],"author":{"@type":"Person","name":"derolol"},"publisher":{"@type":"Organization","name":"Derolol Blog","logo":{"@type":"ImageObject","url":"https://raw.githubusercontent.com/derolol/picgo/main/images/head.png"}},"description":""}</script><link rel="icon" href="https://raw.githubusercontent.com/derolol/picgo/main/images/logo.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://raw.githubusercontent.com/derolol/picgo/main/images/head.png" alt="Derolol Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-26T02:29:09.000Z" title="2024/9/26 上午10:29:09">2024-09-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-26T02:29:09.000Z" title="2024/9/26 上午10:29:09">2024-09-26</time></span><span class="level-item"><a class="link-muted" href="/categories/interview/">interview</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/26/interview/experience/">面试经验</a></p><div class="content"><h2 id="语义分割模型研究">语义分割模型研究</h2>
<h3 id="介绍一下经典的语义分割模型">1. 介绍一下经典的语义分割模型</h3>
<ol type="1">
<li><p><strong>FCN (全卷积网络)</strong> FCN
是最早的端到端语义分割模型之一，它通过去除全连接层并替换为卷积层来实现任意输入尺寸的图像处理。FCN
利用跳跃连接来结合不同层次的特征图以恢复细节信息。</p></li>
<li><p><strong>SegNet</strong> SegNet 基于 VGG16
架构，其主要特点是使用了编码器-解码器结构，并且在解码阶段采用了在编码阶段存储的索引来上采样，从而减少了参数量。</p></li>
<li><p><strong>UNet</strong> UNet
在医学图像分割中特别受欢迎，因为它能够有效地处理小数据集。它包含一个收缩路径（下采样）和一个对称的扩展路径（上采样），并在每个解码步骤中从编码器获取相应的特征图。</p></li>
<li><p><strong>DeepLabV3+</strong> DeepLab
系列是谷歌提出的一组模型，它们使用了空洞卷积（又称扩张卷积）来捕捉多尺度信息，并引入了
ASPP
模块来进一步增强模型的多尺度感受野。DeepLabV3+增加了解码模块来恢复分割细节。</p></li>
<li><p><strong>HRNet</strong> HRNet
专注于在整个网络中保持高分辨率表示，通过并行的流来处理不同分辨率的特征图，并通过交换模块来融合这些特征。这有助于保留更多的细节信息，防止信息损失。</p></li>
<li><p><strong>通道、空间注意力机制</strong> 注意力机制（如 SENet
中的通道注意力或 CBAM
中的空间注意力）允许模型专注于重要的特征图区域，同时抑制不相关的背景噪声，提高模型的准确性。</p></li>
<li><p><strong>ViT (Vision Transformer)</strong> ViT 是一个完全基于
Transformer
架构的视觉模型，它将图像切分为固定大小的补丁，并将这些补丁作为序列传递给标准的
Transformer 编码器。这种设计使得 ViT 可以捕捉全局上下文信息。</p></li>
<li><p><strong>SwinFormer</strong> SwinFormer 是专门为视觉任务设计的
Transformer
变体，它提出了窗口注意力机制来实现局部和非局部的特征交互，同时保持计算效率。</p></li>
<li><p><strong>SegFormer</strong> SegFormer
是一个轻量级的分割模型，它结合了 Transformer 编码器（如
MiT）和简单的解码头来实现高效的多尺度特征提取和分割。</p></li>
<li><p><strong>SAM (Segment Anything Model)</strong> SAM
是一种通用的分割模型，它可以用于任何对象的分割任务而无需特定类别的训练数据。它结合了强大的预训练视觉模型和灵活的提示机制来适应不同的分割需求。</p></li>
</ol>
<p><strong>Q: FCN 如何解决不同大小输入的问题？</strong> A: FCN
通过移除最后的全连接层，代之以卷积层，允许模型接受任意大小的输入图像，并产生相同大小的分割图。</p>
<p><strong>Q: UNet 如何应对数据不足的情况？</strong> A: UNet
的设计包括了一个可以学习到更抽象特征的收缩路径，以及一个可以恢复位置信息的扩展路径，这使得它能够在较少的数据上训练而不会过拟合。</p>
<p><strong>Q: DeepLabV3+中的 ASPP 模块是什么？</strong> A: ASPP（Atrous
Spatial Pyramid Pooling）模块通过不同 rate
的空洞卷积来捕捉不同尺度的信息，从而增强模型对物体不同大小的适应能力。</p>
<p><strong>Q: ViT 是如何处理图像输入的？</strong> A: ViT
首先将输入图像划分为固定的补丁，然后将这些补丁展平成一系列向量，并添加位置嵌入，之后这些向量将被送入
Transformer 编码器进行处理。</p>
<h3 id="隧道病害检测领域常用模型">2. 隧道病害检测领域常用模型</h3>
<p>在隧道病害检测领域，尤其是针对细小裂缝的检测，需要模型具备良好的<strong>细节捕捉</strong>能力和<strong>多尺度感知</strong>能力。以下是一些常用的模型及其特点：</p>
<ol type="1">
<li><p><strong>UNet</strong></p>
<ul>
<li><strong>特点</strong>: UNet
因其在医学图像分割中的成功应用而知名，同样适用于隧道病害检测。通过跳层连接（skip
connections），UNet
能够结合高层语义信息与底层细节信息，这对于细小裂缝的检测非常重要。</li>
<li><strong>应用</strong>: 在隧道检测中，UNet
可以帮助识别裂缝等病害，特别是在数据尺度较小的情况下表现良好。</li>
</ul></li>
<li><p><strong>DeepLabV3+</strong></p>
<ul>
<li><strong>特点</strong>: 使用空洞卷积（Atrous
Convolution）来扩大感受野而不增加参数数量，并引入 ASPP
模块来捕获多尺度信息。DeepLabV3+还增加了额外的解码模块来恢复分割细节。</li>
<li><strong>应用</strong>:
对于隧道病害检测而言，DeepLabV3+的多尺度感知能力非常适合识别不同宽度和长度的裂缝。</li>
</ul></li>
<li><p><strong>SENet (Squeeze-and-Excitation Networks)</strong></p>
<ul>
<li><strong>特点</strong>:
通过引入通道注意力机制来动态地调整通道权重，从而让模型更加关注于那些对于分类任务更重要的特征。</li>
<li><strong>应用</strong>: 在隧道病害检测中，SENet
可以通过加强裂缝区域的特征表达，来提高裂缝识别的连续性。</li>
</ul></li>
<li><p><strong>HRNet (High-Resolution Net)</strong></p>
<ul>
<li><strong>特点</strong>: HRNet
在整个网络中都保持高分辨率的特征图，通过并行的多分支结构来融合不同尺度的信息，避免了在恢复分辨率过程中细节信息的丢失。</li>
<li><strong>应用</strong>:
这种特性对于隧道病害检测尤其有用，因为裂缝往往非常细小，需要保持尽可能高的分辨率来确保准确识别。</li>
</ul></li>
<li><p><strong>SegFormer</strong></p>
<ul>
<li><strong>特点</strong>: SegFormer 结合了 Transformer 编码器（如
MiT）和简单的解码头来实现高效的多尺度特征提取。相比于传统的
CNN，Transformer 能够更好地捕捉全局上下文信息。</li>
<li><strong>应用</strong>: 在隧道病害检测中，SegFormer
可以通过其强大的全局感知能力来识别那些跨越较大区域的裂缝或其他病害。</li>
</ul></li>
</ol>
<p><strong>Q: 在隧道病害检测中，为什么 UNet 的跳层连接很重要？</strong>
A: 跳层连接允许 UNet
在解码过程中重新引入编码阶段丢失的细节信息。这对于细小裂缝的检测至关重要，因为裂缝通常很窄，容易在下采样的过程中丢失。</p>
<p><strong>Q: DeepLabV3+的 ASPP 模块是如何工作的？</strong> A: ASPP
模块使用不同膨胀率的空洞卷积来捕捉不同尺度的信息，这样即使在不改变输出尺寸的情况下，也可以有效地扩大模型的感受野。</p>
<p><strong>Q: SENet 的通道注意力机制如何帮助改进病害检测？</strong> A:
通道注意力机制允许 SENet
根据每个通道的重要性动态地调整权重，这意味着模型可以更加聚焦于那些最能代表病害特征的通道，从而提高检测精度。</p>
<p><strong>Q: 在隧道病害检测中，HRNet 如何保证高分辨率特征图？</strong>
A: HRNet
通过保持多个并行的高分辨率流，并在每一层之间交换信息，从而在整个网络中维持高分辨率特征图。这种方法有助于保留更多细节信息，这对于检测细小裂缝非常重要。</p>
<p><strong>Q: SegFormer 如何在病害检测中发挥作用？</strong> A: SegFormer
利用 Transformer
的强大能力来捕捉全局依赖关系，并通过多尺度特征提取来增强对不同大小病害的检测性能。这对于识别隧道中各种类型的病害非常有效。</p>
<h3 id="如何处理小目标和大目标同时存在于一张图片中的情况">3.
如何处理小目标和大目标同时存在于一张图片中的情况？</h3>
<p>在语义分割任务中，经常会遇到图像中小目标和大目标共存的情况。为了同时有效地检测和分割这些不同尺度的目标，可以采用以下几种策略和技术：</p>
<ol type="1">
<li><p><strong>多尺度注意力金字塔 (Multi-Scale Attention
Pyramid)</strong></p>
<ul>
<li><strong>解释</strong>:
多尺度注意力金字塔通过在不同尺度上应用注意力机制来捕获不同大小的目标。这通常涉及到构建一个多尺度特征金字塔，每个尺度上的特征图都会经过注意力机制处理，以突出不同尺度的目标。</li>
<li><strong>例子</strong>: 比如 DeepLab 系列中的 ASPP（Atrous Spatial
Pyramid
Pooling）模块就是一种典型的多尺度处理方式，它通过不同膨胀率的卷积来捕捉多尺度信息。</li>
</ul></li>
<li><p><strong>混合 CNN 和 Transformer (Hybrid CNN and Transformer
Models)</strong></p>
<ul>
<li><strong>解释</strong>: 混合 CNN 和 Transformer
模型结合了传统卷积神经网络在局部特征提取方面的优势和 Transformer
在捕获长距离依赖关系方面的强大能力。这种组合可以在不同尺度上同时处理局部和全局信息。</li>
<li><strong>例子</strong>: SegFormer 就是一个实例，它使用了 Transformer
编码器（如
MiT）来提取多尺度特征，并结合了简单的解码头来进行最终的分割预测。</li>
</ul></li>
</ol>
<p><strong>Q:
为什么多尺度注意力金字塔对于处理小目标和大目标是有效的？</strong> A:
多尺度注意力金字塔通过在多个尺度上进行特征提取，使得模型可以在不同级别的细节上关注目标，从而更好地捕捉到小目标的细节和大目标的整体形状。</p>
<p><strong>Q: SegFormer 如何结合 CNN 和 Transformer 的优点？</strong> A:
SegFormer 使用了基于 Transformer
的编码器来捕捉全局上下文信息，并通过多尺度特征提取来增强对不同大小目标的理解。同时，它的解码头设计简单高效，可以很好地将多尺度特征融合在一起，以实现高质量的分割结果。</p>
<p><strong>Q: 在实际应用中，如何选择合适的多尺度处理方法？</strong> A:
选择多尺度处理方法时，应考虑应用场景的具体需求。如果场景中存在大量的小目标，则应选择那些能够较好地保留细节信息的方法；而对于包含大范围目标的场景，则可能需要更强的全局感知能力。</p>
<p><strong>Q:
除了多尺度处理，还有哪些技术可以用来改善小目标和大目标的分割效果？</strong>
A: 另外一些技术还包括使用金字塔结构（如
FPN）、增强数据（如数据扩增）、改进损失函数（如 Focal
Loss）等方法，这些都可以辅助提升模型在不同尺度目标上的表现。</p>
<h3 id="你在实际项目中使用过哪些语义分割模型遇到了什么挑战怎么解决">4.
你在实际项目中使用过哪些语义分割模型？遇到了什么挑战？怎么解决？</h3>
<p>在实际项目中，我使用过多种语义分割模型来处理隧道病害检测的任务，包括但不限于
UNet、DeepLabV3+、HRNet 和
SegFormer。在具体的应用过程中，确实遇到了一些挑战，并采取了相应的解决方案。</p>
<ol type="1">
<li><p><strong>裂缝和瓷砖剥落病害尺度不平衡</strong></p>
<ul>
<li><strong>挑战</strong>:
不同尺度的病害（如细小裂缝和大面积的瓷砖剥落）在图像中占比不同，这可能导致模型对某一类病害的检测能力较弱。</li>
<li><strong>解决方案</strong>:
<ul>
<li>使用加权交叉熵损失函数，或 Focal
Loss，来平衡不同类别之间的损失贡献，从而提高小目标的检测能力。</li>
<li>结合 Transformer 和 CNN 的优势，利用 Transformer
捕捉全局信息，同时使用 CNN
来提取局部特征，以增强模型对不同尺度病害的感知能力。</li>
</ul></li>
</ul></li>
<li><p><strong>病害图像背景复杂</strong></p>
<ul>
<li><strong>挑战</strong>:
背景复杂度高会干扰模型对病害关键特征的提取，导致误检或漏检。</li>
<li><strong>解决方案</strong>:
<ul>
<li>使用原型特征提取方法，该方法能够学习到特定类别的原型特征，有助于在复杂背景下提取出病害的关键特征。</li>
<li>利用 VQGAN 的预训练 CodeBook
来提取更为鲁棒的特征表示，增强模型的抗干扰能力。</li>
</ul></li>
</ul></li>
<li><p><strong>标注不准确</strong></p>
<ul>
<li><strong>挑战</strong>:
数据标注过程中可能会出现误差，导致模型训练偏差或泛化能力下降。</li>
<li><strong>解决方案</strong>:
<ul>
<li>采用软标签的学习方式，即在训练过程中使用带有不确定性的标签，而非硬性分配标签，这样可以减弱损失函数的强约束，使模型更具弹性。</li>
<li>使用边缘优化方法，如
PointRend，来改进分割边界，或者采用边缘再分割技术，通过形态学操作（如膨胀、腐蚀）来选取合适的像素点，提高分割的准确性。</li>
</ul></li>
</ul></li>
</ol>
<p><strong>Q: Focal Loss 是如何解决类别不平衡问题的？</strong> A: Focal
Loss
通过降低易分类样本的权重，从而更加关注难以分类的样本。这样可以减轻类别不平衡带来的影响，尤其是在小目标检测中表现得尤为明显。</p>
<p><strong>Q: Transformer 和 CNN 的结合如何提高模型性能？</strong> A:
Transformer 擅长捕捉全局依赖关系，而 CNN
则在局部特征提取方面表现出色。将两者结合起来可以互补各自的优势，使得模型既能捕捉到局部细节又能理解整体上下文。</p>
<p><strong>Q: 原型特征提取方法是如何工作的？</strong> A: ProtoPNet
通过学习一组原型特征，并在测试时计算输入图像与这些原型特征之间的相似度，从而决定分类结果。原型特征为一类像素特征的均值，且随着训练不断变化。这种方法可以增强模型对特定类别的理解，并提高其在复杂背景下的鲁棒性。</p>
<p><strong>Q: 使用 VQGAN 的预训练 CodeBook 有什么好处？</strong> A: 使用
VQGAN 的预训练 CodeBook
可以帮助模型学习到更加紧凑和有意义的离散特征表示，这对于处理复杂背景下的病害检测任务非常有帮助，可以减少背景噪声的影响。</p>
<p><strong>Q: PointRend 是如何优化分割边界的？</strong> A: PointRend
通过在分割边界处选择不确定性较高的像素点重预测，来细化分割结果。这种方法可以在保持较高效率的同时，显著提高分割边界的准确性。</p>
<p><strong>Q: 6. 除了
Self-Attention，还有哪些机制可以增强模型的表达能力？</strong> A:
（层归一化（Layer
Normalization）可以帮助模型更好地学习长距离依赖；残差连接（Residual
Connections）有助于梯度流动；使用 Transformer 中的多头注意力机制）</p>
<h2 id="损失函数">损失函数</h2>
<h3 id="介绍一下常用的损失函数">1. 介绍一下常用的损失函数</h3>
<ol type="1">
<li><p><strong>交叉熵损失（Cross Entropy Loss）</strong></p>
<ul>
<li><p><strong>解释</strong>:
交叉熵损失是最常见的分类损失函数之一，它衡量的是模型预测的概率分布与真实标签的概率分布之间的差异。</p></li>
<li><p><strong>代码示例</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CrossEntropyLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, reduction=<span class="string">'mean'</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(CrossEntropyLoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.reduction = reduction</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, label</span>):</span><br><span class="line">        <span class="comment"># pred (B, C, H, W)</span></span><br><span class="line">        <span class="comment"># label (B, H, W)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(label.shape) &lt; <span class="built_in">len</span>(pred.shape):  <span class="comment"># 如果标签不是one-hot形式</span></span><br><span class="line">            label = F.one_hot(label, num_classes=pred.shape[<span class="number">1</span>])</span><br><span class="line">        pred = F.softmax(pred, dim=<span class="number">1</span>)</span><br><span class="line">        loss = -label * torch.log(pred)</span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = loss * self.weight.view(<span class="number">1</span>, - <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.reduction == <span class="string">'mean'</span>:</span><br><span class="line">            <span class="keyword">return</span> loss.mean()</span><br><span class="line">        <span class="keyword">elif</span> self.reduction == <span class="string">'sum'</span>:</span><br><span class="line">            <span class="keyword">return</span> loss.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p><strong>Focal Loss</strong></p>
<ul>
<li><p><strong>解释</strong>: Focal Loss
旨在解决类别不平衡的问题，通过在交叉熵的基础上增加一个调节因子来降低容易分类样本的权重，增加难分类样本的权重。</p></li>
<li><p><strong>代码示例</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>, reduction=<span class="string">'mean'</span>, gamma=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(FocalLoss, self).__init__()</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.reduction = reduction</span><br><span class="line">        self.gamma = gamma</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, label</span>):</span><br><span class="line">        <span class="comment"># pred (B, C, H, W)</span></span><br><span class="line">        <span class="comment"># label (B, H, W)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(label.shape) &lt; <span class="built_in">len</span>(pred.shape):</span><br><span class="line">            label = F.one_hot(label, num_classes=pred.shape[<span class="number">1</span>])</span><br><span class="line">        pred = F.softmax(pred, dim=<span class="number">1</span>)</span><br><span class="line">        pt = torch.where(label &gt; <span class="number">0</span>, pred, <span class="number">1</span> - pred)</span><br><span class="line">        loss = -torch.<span class="built_in">pow</span>(<span class="number">1</span> - pt, self.gamma) * label * torch.log(pt)</span><br><span class="line">        <span class="keyword">if</span> self.weight <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = loss * self.weight.view(<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.reduction == <span class="string">'mean'</span>:</span><br><span class="line">            <span class="keyword">return</span> loss.mean()</span><br><span class="line">        <span class="keyword">elif</span> self.reduction == <span class="string">'sum'</span>:</span><br><span class="line">            <span class="keyword">return</span> loss.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p><strong>Dice 损失</strong></p>
<ul>
<li><p><strong>解释</strong>: Dice
损失通常用于分割任务中，特别是当需要关注分割边界时。它定义为两个集合交集的两倍除以它们的并集。</p></li>
<li><p><strong>公式</strong>: ( DICE = 1 - )，其中( X )是预测结果，( Y
)是真实标签。</p></li>
<li><p><strong>代码示例</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DiceLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DiceLoss, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, label</span>):</span><br><span class="line">        smooth = <span class="number">1.</span></span><br><span class="line">        pred = F.softmax(pred, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(label.shape) &lt; <span class="built_in">len</span>(pred.shape):</span><br><span class="line">            label = F.one_hot(label, num_classes=pred.shape[<span class="number">1</span>])</span><br><span class="line">        intersection = (pred * label).<span class="built_in">sum</span>(dim=(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        dice_score = (<span class="number">2.</span> * intersection + smooth) / (pred.<span class="built_in">sum</span>(dim=(<span class="number">2</span>, <span class="number">3</span>)) + label.<span class="built_in">sum</span>(dim=(<span class="number">2</span>, <span class="number">3</span>)) + smooth)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - dice_score.mean()</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ol>
<p><strong>Q: 为什么交叉熵函数在不平衡数据表现不佳？</strong> A:
交叉熵函数在不平衡数据集中表现不佳的原因在于，它会过度强调多数类别的样本，而忽略少数类别的样本。在不平衡数据集中，少数类别的样本往往包含更有价值的信息，但交叉熵损失函数并没有专门对待这些样本，导致模型倾向于偏向多数类别。</p>
<p><strong>Q: Focal Loss 是如何解决类别不平衡的问题的？</strong> A:
Focal Loss 通过引入一个调节因子( (1 - p_t)^{} )，其中( p_t
)是模型对正确类别的预测概率，(
)是调节因子的指数。这个调节因子降低了容易分类样本的贡献，同时增加了难分类样本的贡献，从而使得模型更加关注那些难以分类的样本。</p>
<p><strong>Q: Class Weight 是如何帮助平衡数据的？</strong> A: Class
Weight
是通过为不同类别赋予不同的权重来实现的，这样可以调整损失函数中各类别对总损失的贡献比例。在不平衡数据集中，可以为少数类别赋予更高的权重，从而增加它们在训练过程中的重要性。</p>
<p><strong>Q: 如何平衡正负样本的比例来改善模型性能？</strong> A:
平衡正负样本比例可以通过多种方法实现，例如过采样少数类别、欠采样多数类别、使用合成样本（如
SMOTE）、调整 Class Weight
等。这些方法可以单独使用或组合使用，以达到更好的模型训练效果。此外，还可以在训练过程中动态调整样本权重，以进一步优化模型性能。</p>
<h2 id="数据集构建">数据集构建</h2>
<h3 id="数据处理的过程">1. <strong>数据处理的过程</strong></h3>
<ul>
<li><strong>数据收集</strong>: 收集来自不同来源的原始数据。</li>
<li><strong>预处理</strong>: 包括数据格式转换、缩放、裁剪等操作。</li>
<li><strong>清洗</strong>: 移除或修正错误、重复或无关的数据。</li>
<li><strong>标注</strong>:
对数据进行标记，以便机器学习模型可以学习到正确的模式。</li>
<li><strong>划分</strong>:
将数据分成训练集、验证集和测试集，用于模型训练、调参和评估。</li>
</ul>
<h3 id="数据收集">2. <strong>数据收集</strong></h3>
<ul>
<li><strong>采集车采集隧道衬砌图像</strong>:
使用专门的采集设备在隧道内拍摄衬砌图像，确保图像质量和涵盖不同类型的衬砌材料。</li>
</ul>
<h3 id="数据标注">3. <strong>数据标注</strong></h3>
<ul>
<li><strong>LabelMe</strong>: 使用 LabelMe
这样的工具进行手动标注，确保标注的准确性和一致性。</li>
</ul>
<h3 id="数据预处理">4. <strong>数据预处理</strong></h3>
<ul>
<li><strong>局部匀光算法</strong>:
对图像进行光照均匀化处理，消除光照不均带来的影响。</li>
<li><strong>数据分块</strong>:
将大图像分割成若干个小块，便于处理和标注。</li>
</ul>
<h3 id="数据清洗">5. <strong>数据清洗</strong></h3>
<ul>
<li><strong>去除重复数据</strong>:
通过哈希或特征匹配等方式识别并删除重复项。</li>
<li><strong>修复损坏文件</strong>: 检查并修复损坏的图像文件。</li>
<li><strong>清理噪声</strong>: 去除不需要的对象或背景干扰。</li>
</ul>
<h3 id="数据划分">6. <strong>数据划分</strong></h3>
<ul>
<li><strong>随机划分</strong>:
使用随机种子将数据集分成训练、验证和测试集。</li>
<li><strong>按类别划分</strong>:
确保每个子集中都有各个类别的代表性样本。</li>
</ul>
<h3 id="如何处理数据集中存在的标注错误">7.
<strong>如何处理数据集中存在的标注错误？</strong></h3>
<ul>
<li><strong>复查标注</strong>:
定期复查已有的标注，确保标注的一致性和准确性。</li>
<li><strong>使用一致性检查</strong>:
应用一致性检查工具来发现和纠正标注错误。</li>
<li><strong>引入专家审查</strong>:
让领域专家复审标注结果，尤其是对于复杂的案例。</li>
</ul>
<h3 id="在数据集构建过程中如何保证数据的多样性和代表性">8.
<strong>在数据集构建过程中，如何保证数据的多样性和代表性？</strong></h3>
<ul>
<li><strong>涵盖不同场景</strong>:
确保数据覆盖隧道的不同部分，如墙壁、天花板、地面等。</li>
<li><strong>不同条件</strong>:
包括白天、夜晚、晴天、雨天等多种天气和光照条件。</li>
<li><strong>不同材质</strong>:
包括瓷砖、混凝土、金属等多种衬砌材料。</li>
<li><strong>不同病害类型</strong>:
包括裂缝、剥落、渗水等多种病害形式。</li>
</ul>
<h3 id="有哪些工具或技术可以用来自动化数据标注过程">9.
<strong>有哪些工具或技术可以用来自动化数据标注过程？</strong></h3>
<ul>
<li><strong>Paddle</strong>: 使用 Paddle
框架提供的工具和服务进行自动化的数据标注。</li>
<li><strong>LabelStudio</strong>: LabelStudio
是一个开源的标注工具，支持多种数据类型和标注任务，可以用于简化数据标注流程。</li>
</ul>
<p><strong>Q: 局部匀光算法是如何工作的？</strong> A:
局部匀光算法通常通过调整图像的局部对比度或亮度来均匀化光照条件。计算局部块的平均灰度，上采样和高斯模糊得到亮度图，计算原图与亮度图的差异还原亮度分布。还可以使用直方图均衡化、Retinex
算法或自适应直方图均衡化（CLAHE）等方法来改善光照不均的问题。</p>
<p><strong>Q: 数据分块的好处是什么？</strong> A:
数据分块可以使处理和标注工作更加高效。通过将图像分割成小块，可以更容易地进行并行处理，同时也有助于标注人员专注于图像的特定区域。</p>
<p><strong>Q: 数据清洗中的“清理噪声”具体指的是什么？</strong> A:</p>
<p><strong>Q: 如何确保数据集划分的合理性？</strong> A:
确保数据集划分合理的方法之一是使用分层抽样，这样可以确保每个子集中都有各个类别的代表性样本。此外，可以使用交叉验证来评估模型在不同子集上的表现。</p>
<p><strong>Q: 自动化数据标注技术的局限性是什么？</strong> A:
自动化数据标注虽然提高了效率，但也可能存在误标的情况，尤其是在数据复杂或变化多端的情况下。因此，通常还需要人工复查和修正标注结果。</p>
<h2 id="训练方法研究">训练方法研究</h2>
<h3 id="mmcv">1. <strong>MMCV</strong></h3>
<ul>
<li><strong>解释</strong>: MMCV 是一个基于 PyTorch
的开放源码计算机视觉工具箱，它提供了丰富的模型实现、数据处理和训练框架。</li>
<li><strong>用途</strong>: MMCV
可以帮助快速搭建和训练模型，同时也提供了很多实用功能，如数据增强、模型融合等。</li>
</ul>
<h3 id="训练框架">2. <strong>训练框架</strong></h3>
<ul>
<li><strong>Config</strong>:
配置文件用于定义整个训练过程的参数，包括数据路径、模型结构、损失函数、优化器等。</li>
<li><strong>Data</strong>: 数据加载器负责读取、预处理和批处理数据。</li>
<li><strong>Model</strong>: 模型定义，包括网络结构和前向传播逻辑。</li>
<li><strong>Loss</strong>:
损失函数用于量化模型预测与真实标签之间的差距。</li>
<li><strong>Trainer</strong>:
训练循环逻辑，包括前向传播、反向传播、优化更新等。</li>
</ul>
<h3 id="pytorchlightning">3. <strong>PytorchLightning</strong></h3>
<ul>
<li><strong>解释</strong>: PytorchLightning 是一个用于简化 PyTorch
模型开发的库，提供了一套简洁的 API 来管理训练流程。</li>
<li><strong>优点</strong>:
减少了样板代码，方便配置和调试，支持多种训练策略如 GPU
分布式训练、混合精度训练等。</li>
</ul>
<h3 id="学习率的选择">4. <strong>学习率的选择</strong></h3>
<ul>
<li><strong>解释</strong>:
学习率决定了模型参数更新的速度。过高会导致训练不稳定甚至发散，过低则会使训练速度过慢。</li>
<li><strong>策略</strong>: 可以通过学习率查找（Learning Rate
Finder）来找到合适的初始学习率。</li>
</ul>
<h3 id="优化器的选择">5. <strong>优化器的选择</strong></h3>
<ul>
<li><strong>解释</strong>: 优化器决定了梯度下降的方式，常用的有
SGD、Adam、RMSprop 等。</li>
<li><strong>选择</strong>: 根据任务特性和模型结构选择合适的优化器，例如
Adam 适合稀疏数据，SGD 适合大规模数据集。</li>
</ul>
<h3 id="显存问题">6. <strong>显存问题</strong></h3>
<ul>
<li><strong>解释</strong>:
训练深度学习模型时，显存不足是一个常见问题。</li>
<li><strong>解决</strong>:
可以通过梯度累积、模型剪枝、分批加载数据等方式缓解显存压力。</li>
</ul>
<h3 id="如何有效地使用迁移学习来加速模型训练">7.
<strong>如何有效地使用迁移学习来加速模型训练？</strong></h3>
<ul>
<li><strong>使用预训练模型作为初始权重</strong>:
从预训练模型加载权重，可以加速收敛并提高性能。</li>
<li><strong>冻结基础层，仅训练顶层</strong>:
在训练初期可以冻结预训练层，只训练新添加的层。</li>
<li><strong>适应性调整预训练模型的输出层以匹配新的任务</strong>:
修改输出层以适应新的任务需求。</li>
</ul>
<h3 id="如何设置学习率衰减策略来避免过拟合">8.
<strong>如何设置学习率衰减策略来避免过拟合？</strong></h3>
<ul>
<li><strong>使用学习率调度器如 StepLR、Cosine Annealing 等</strong>:
通过周期性地降低学习率来促进收敛。</li>
<li><strong>观察验证集上的性能变化来动态调整学习率</strong>:
当验证集性能不再提升时，可以适当降低学习率。</li>
<li><strong>使用早停法（Early Stopping）</strong>:
在验证集性能不再改善时提前终止训练。</li>
</ul>
<h3 id="在训练过程中如何监控和诊断模型的训练状态">9.
<strong>在训练过程中，如何监控和诊断模型的训练状态？</strong></h3>
<ul>
<li><strong>使用 TensorBoard 或其他可视化工具来跟踪损失和指标</strong>:
监控训练过程中的损失曲线和指标变化。</li>
<li><strong>定期保存检查点并进行评估</strong>:
保存中间训练结果，便于后续评估或恢复训练。</li>
<li><strong>记录训练过程中的关键参数和配置</strong>:
保持训练配置的一致性和可重复性。</li>
</ul>
<h3 id="ddp-distributed-data-parallel">10. <strong>DDP (Distributed Data
Parallel)</strong></h3>
<ul>
<li><strong>解释</strong>: DDP 是 PyTorch
中的一个分布式训练工具，允许多个 GPU 并行训练同一个模型。</li>
<li><strong>使用</strong>: 可以通过设置
<code>torch.nn.parallel.DistributedDataParallel</code> 来启用 DDP
训练。</li>
</ul>
<h3 id="混合精度">11. <strong>混合精度</strong></h3>
<ul>
<li><strong>解释</strong>:
混合精度训练是指在模型训练过程中同时使用单精度（32 位）和半精度（16
位）浮点运算。</li>
<li><strong>优势</strong>:
可以减少内存占用，加快训练速度，同时保持较高的精度。</li>
</ul>
<p><strong>Q: MMDetection 有哪些主要组件？</strong> A: MMDetection
主要包括数据读取、模型定义、训练流程管理、评估工具等多个组件，支持多种模型和任务的快速开发。</p>
<p><strong>Q: 如何选择合适的优化器？</strong> A:
选择优化器时需要考虑任务的特性和数据集的特点。例如，对于稀疏数据，Adam
通常表现较好；而对于大规模数据集，SGD
由于其更快的收敛速度可能是更好的选择。</p>
<p><strong>Q: 如何解决显存不足的问题？</strong> A:
可以通过使用梯度累积、模型剪枝、数据分批加载等方法来缓解显存不足的问题。此外，还可以考虑使用更大的显卡或者分布式训练方案。</p>
<p><strong>Q: 学习率查找是如何工作的？</strong> A:
学习率查找通过逐渐增加学习率并观察损失的变化趋势来确定一个好的初始学习率。通常会在训练初期执行一次，以找到损失开始显著下降的学习率值。</p>
<p><strong>Q: 如何使用早停法来避免过拟合？</strong> A:
在训练过程中，当验证集的性能不再提高时，可以停止训练。这通常通过监测验证集上的损失或准确率来实现，当这些指标在一个预定的周期内没有改善时，就触发早停。</p>
<h2 id="低光增强及图像复原模型研究">低光增强及图像复原模型研究</h2>
<h3 id="refinxnet">1. <strong>RefinxNet</strong></h3>
<ul>
<li><strong>解释</strong>: RefinxNet 基于 Refinx
原理分离亮度和细节。</li>
<li><strong>特点</strong>: RefinxNet
通过多级特征融合，增强了对细节的捕捉能力，并且使用残差学习来减少训练难度。</li>
</ul>
<h3 id="zero-dce">2. <strong>Zero-DCE</strong></h3>
<ul>
<li><strong>解释</strong>: Zero-DCE
是一种无参考的低光图像增强方法，它不需要任何参考图像即可完成增强任务。</li>
<li><strong>特点</strong>: Zero-DCE
通过学习图像的亮度和色彩分布来调整图像，使得在没有任何参考图像的情况下也能获得较好的增强效果。</li>
</ul>
<h3 id="ddpm">3. <strong>DDPM</strong></h3>
<ul>
<li><strong>解释</strong>: DDPM（Diffusion Denoising Probabilistic
Models）是一种基于扩散过程的图像生成模型，也可以应用于图像复原任务。</li>
<li><strong>特点</strong>: DDPM
通过逐步去除噪声来恢复图像，适用于多种图像复原任务。</li>
</ul>
<h3 id="controlnet">4. <strong>ControlNet</strong></h3>
<ul>
<li><strong>解释</strong>: ControlNet
是一种可以控制生成过程的模型，可以在图像复原任务中引入额外的控制信号。</li>
<li><strong>特点</strong>: ControlNet
可以根据额外的输入（如边缘图、分割图等）来引导图像复原过程，提高复原的准确性和可控性。</li>
</ul>
<h3 id="locallightenhance">5. <strong>LocalLightEnhance</strong></h3>
<ul>
<li><strong>解释</strong>: LocalLightEnhance
是一种局部光照增强方法，通过局部调整图像的光照来提高图像质量。</li>
<li><strong>特点</strong>: LocalLightEnhance
更加注重局部细节的恢复，适用于需要精细调整光照的场景。</li>
</ul>
<h3 id="position-embedding">6. <strong>Position Embedding</strong></h3>
<ul>
<li><strong>解释</strong>: 位置嵌入（Position Embedding）是在
Transformer 模型中引入的一种机制，用于捕捉序列中元素的位置信息。</li>
<li><strong>公式</strong>: ( pos<em>{(2i)} = (x / i</em>{}) ), (
pos<em>{(2i+1)} = (x / i</em>{}) )</li>
<li><strong>类型</strong>:
包括相对位置编码和空间位置编码，前者用于捕捉序列元素之间的相对位置，后者用于标记序列中元素的空间位置。</li>
</ul>
<h3 id="hunyuandit">7. <strong>HunyuanDiT</strong></h3>
<ul>
<li><strong>解释</strong>: HunyuanDiT
是一种用于图像复原的扩散模型，结合了多尺度特征提取和注意力机制。</li>
<li><strong>特点</strong>: HunyuanDiT
通过多尺度特征提取来捕捉不同层次的细节，并通过注意力机制来加强重要特征的表达。</li>
</ul>
<h3 id="如何评估低光图像增强算法的效果">8.
<strong>如何评估低光图像增强算法的效果？</strong></h3>
<ul>
<li><strong>定量指标</strong>: 使用 LOE（Low Light
Enhancement）、PSNR（峰值信噪比）、SSIM（结构相似性指数）等指标来评估图像质量。</li>
<li><strong>主观反馈</strong>:
通过用户研究或专家评审来获取关于图像视觉效果的主观反馈。</li>
<li><strong>视觉效果</strong>:
比较增强前后图像的视觉效果，评估算法在实际应用中的表现。</li>
</ul>
<h3 id="对于极端低光条件下的图像有哪些有效的增强方法">8.
<strong>对于极端低光条件下的图像，有哪些有效的增强方法？</strong></h3>
<ul>
<li><strong>增强曝光度</strong>:
通过增加曝光度来提高图像的整体亮度。</li>
<li><strong>局部调整</strong>:
使用局部光照增强方法来恢复图像的细节。</li>
<li><strong>多帧融合</strong>:
通过融合多张连续拍摄的低光图像来减少噪声并提高图像质量。</li>
<li><strong>预处理</strong>:
在增强前进行预处理，如去除噪声或增强对比度。</li>
</ul>
<h3 id="如何利用先验知识来改进图像复原模型">9.
<strong>如何利用先验知识来改进图像复原模型？</strong></h3>
<ul>
<li><strong>物理模型</strong>:
引入物理模型来模拟成像过程，帮助模型更好地理解图像退化的原因。</li>
<li><strong>场景特定知识</strong>:
根据特定场景的特点，如光照方向、纹理特征等，对模型进行定制化调整。</li>
<li><strong>上下文信息</strong>:
利用上下文信息（如图像中的语义信息）来指导图像复原过程。</li>
<li><strong>多模态信息</strong>:
结合其他模态的数据（如深度信息、语义分割图等）来增强图像复原的效果。</li>
</ul>
<p><strong>Q: RefinxNet 中的多尺度特征融合是如何实现的？</strong> A:</p>
<p><strong>Q: Zero-DCE 的优势是什么？</strong> A: Zero-DCE
的最大优势在于它不需要参考图像即可完成增强任务，这使得它在实际应用中更加便捷。</p>
<p><strong>Q: DDPM 在图像复原中的作用是什么？</strong> A: DDPM
通过逐步去除图像中的噪声来恢复图像的原始信息，适用于多种复原任务。</p>
<p><strong>Q: ControlNet 在图像复原中的应用有哪些？</strong> A:
ControlNet
可以通过引入额外的控制信号来引导图像复原过程，从而实现更精确的复原效果。</p>
<p><strong>Q: 如何选择合适的定量指标来评估图像增强的效果？</strong> A:
选择指标时需要考虑具体的评估目标，如 LOE 侧重于低光环境下的增强效果，而
PSNR 和 SSIM 则更多关注图像的整体质量。</p>
<p><strong>Q: 在极端低光条件下，多帧融合为什么有效？</strong> A:
多帧融合可以利用多张图像中的信息来补偿单张图像中的信息不足，从而提高图像质量。</p>
<p><strong>Q: 如何利用场景特定知识来改进图像复原模型？</strong> A:
可以根据场景的特点，如光照条件、纹理特征等，对模型进行定制化调整，使其更适合特定场景的应用。</p>
<h2 id="图像处理算法">图像处理算法</h2>
<ol type="1">
<li><p><strong>低通滤波</strong></p>
<ul>
<li><strong>解释</strong>:
低通滤波器用于平滑图像，去除高频噪声，保留低频成分。</li>
<li><strong>应用</strong>: 低通滤波常用于图像去噪、模糊处理等场景。</li>
<li><strong>例子</strong>:
常见的低通滤波器有均值滤波器、高斯滤波器等。</li>
</ul></li>
<li><p><strong>边缘提取算法</strong></p>
<ul>
<li><strong>解释</strong>:
边缘提取算法用于检测图像中的边缘，即像素强度的急剧变化。</li>
<li><strong>应用</strong>:
边缘检测广泛应用于图像分割、特征识别等领域。</li>
<li><strong>例子</strong>: 常见的边缘提取算子有 Sobel 算子、Canny
边缘检测、Prewitt 算子等。</li>
</ul></li>
<li><p><strong>在不同的应用场景中，如何选择适合的滤波器？</strong></p>
<ul>
<li><strong>根据需求选择滤波器类型</strong>:
例如，去噪可以选择高斯滤波，边缘检测可以选择 Sobel 算子。</li>
<li><strong>考虑滤波器的频率响应特性</strong>:
不同滤波器对不同频率成分的处理效果不同，需根据实际需求选择合适的滤波器。</li>
</ul></li>
<li><p><strong>如何结合多种边缘提取算法来获得更好的效果？</strong></p>
<ul>
<li><strong>组合使用</strong>:
可以将多种边缘提取算法的结果进行组合，例如先用 Canny
边缘检测提取粗略边缘，然后再用 Sobel 算子细化边缘。</li>
<li><strong>多尺度处理</strong>:
在不同尺度上应用不同的边缘检测算法，然后综合结果，以提高边缘检测的鲁棒性。</li>
<li><strong>融合算法</strong>:
利用融合算法（如投票机制）来综合多种边缘检测算法的结果，以获得更准确的边缘。</li>
</ul></li>
<li><p><strong>除了传统的边缘检测算法，还有哪些现代方法？</strong></p>
<ul>
<li><strong>深度学习方法</strong>:
使用卷积神经网络（CNN）进行边缘检测，例如基于 U-Net、SegNet
等网络架构的边缘检测模型。</li>
<li><strong>超像素分割</strong>:
利用超像素分割技术，将图像分割成多个超像素区域，然后在超像素级别进行边缘检测。</li>
<li><strong>图割方法</strong>:
利用图论中的图割方法来检测图像中的边缘。</li>
<li><strong>主动轮廓模型（Snake 模型）</strong>:
通过能量最小化的方法来寻找图像中的边缘。</li>
</ul></li>
</ol>
<p><strong>Q: 高斯滤波器和平均滤波器有什么区别？</strong> A:
高斯滤波器通过高斯函数加权平均邻域内的像素值，可以有效地保留图像的主要特征，同时去除噪声。而平均滤波器则是简单地取邻域内像素的平均值，可能会导致图像模糊。</p>
<p><strong>Q: Sobel 算子的工作原理是什么？</strong> A: Sobel
算子通过两个 3x3
的卷积核分别对图像进行水平和垂直方向的卷积，从而计算图像在两个方向上的梯度，进而检测出边缘。</p>
<p><strong>Q: 在图像处理中，如何选择合适的滤波器大小？</strong> A:
滤波器的大小取决于需要处理的特征的尺度。较大的滤波器可以处理更大范围的特征，但可能会丢失细节；较小的滤波器则更适合处理局部特征。</p>
<p><strong>Q: 如何评估边缘检测算法的效果？</strong> A:
可以通过定量指标（如边缘检测的准确率、召回率等）和定性评价（如视觉效果）来评估边缘检测算法的效果。此外，还可以使用人工标注的边缘作为基准来比较算法的性能。</p>
<p><strong>Q: 深度学习在边缘检测中的优势是什么？</strong> A:
深度学习方法可以自动学习特征表示，具有很强的表达能力和适应性，可以处理复杂的边缘检测任务，并且在大数据集上有很好的表现。</p>
<h2 id="分割边缘优化">分割边缘优化</h2>
<ol type="1">
<li>PointRend</li>
<li>Multimul DataSyn</li>
<li>SegRefiner</li>
<li>如何评价分割边缘的质量？</li>
<li>在分割任务中，如何平衡速度和精度？</li>
<li>有没有尝试过将其他领域的技术应用于分割边缘优化？</li>
</ol>
<h2 id="transformer-模型">Transformer 模型</h2>
<ol type="1">
<li>Transformer 模型是如何处理长依赖关系的？</li>
<li>如何将 Transformer 应用于非自然语言处理的任务？</li>
<li>Transformer 模型的局限性是什么？
（计算成本高，尤其是在长序列上；训练数据需求量大；难以捕捉局部特征）</li>
</ol>
<h2 id="diffusion-模型">Diffusion 模型</h2>
<h3 id="diffusion-模型的训练过程">1. <strong>Diffusion
模型的训练过程</strong></h3>
<ul>
<li><strong>正向扩散过程</strong>:
在这一过程中，原始数据被逐渐添加高斯噪声，直到变成纯噪声为止。这一过程可以看作是一个数据退化的过程，目的是构造一个从清晰数据到噪声的连续分布演变。</li>
<li><strong>逆向扩散过程</strong>:
该过程尝试从噪声中逐步去除噪声，逐步重建原始数据。此过程涉及训练一个模型，使其能够预测在某一步骤中应该去除多少噪声。</li>
</ul>
<h3 id="diffusion-模型与-gan-模型的区别">2. <strong>Diffusion 模型与 GAN
模型的区别</strong></h3>
<ul>
<li><strong>显式地学习噪声分布</strong>: Diffusion
模型通过显式地学习噪声分布来生成数据，而 GAN
则是通过生成器和判别器之间的对抗训练来间接学习数据分布。</li>
</ul>
<h3 id="如何在-diffusion-模型中加入条件信息">3. <strong>如何在 Diffusion
模型中加入条件信息？</strong></h3>
<ul>
<li><strong>使用条件向量作为输入的一部分</strong>:
条件信息可以直接作为模型输入的一部分，帮助指导生成过程。</li>
<li><strong>在生成过程中加入外部信息</strong>:
例如，在文本到图像生成中，可以将文本描述嵌入到模型中，如 StableDiffusion
通过交叉注意力机制融合特征。</li>
<li><strong>ControlNet</strong>:
在某些情况下，可以通过增加一个可训练的分支并将条件信息通过跳层连接引入，类似于
ControlNet 的做法。</li>
</ul>
<h3 id="在图像生成任务中diffusion-模型相比传统方法有什么优势">4.
<strong>在图像生成任务中，Diffusion
模型相比传统方法有什么优势？</strong></h3>
<ul>
<li><strong>学习分布时任务目标更简单</strong>: Diffusion
模型通过逐步添加和去除噪声来学习数据分布，这比直接学习复杂的高维数据分布要简单得多。</li>
<li><strong>速度较慢</strong>:
尽管任务目标简单，但由于需要多次迭代去除噪声，因此生成过程相对缓慢。</li>
</ul>
<h3 id="如何评估-diffusion-模型的生成质量">5. <strong>如何评估 Diffusion
模型的生成质量？</strong></h3>
<ul>
<li><strong>结果容易模糊</strong>: Diffusion
模型由于其生成过程的本质，可能会导致生成的图像模糊不清。评估时可以使用诸如
Fréchet Inception Distance (FID) 或 Inception Score (IS)
等指标来量化生成图像的质量。</li>
<li><strong>定性评估</strong>:
除了量化指标外，还可以通过人工视觉评估来检查生成图像的真实感和多样性。</li>
</ul>
<h3 id="diffusion-推理加速">6. <strong>Diffusion 推理加速</strong></h3>
<ul>
<li><strong>并行化</strong>: 利用 GPU
的并行计算能力来加速每一步的去噪过程。</li>
<li><strong>采样步数减少</strong>: DDIM
通过减少去噪步骤的数量来加速推理，但这可能会影响生成图像的质量。</li>
<li><strong>模型剪枝</strong>:
通过对模型进行剪枝，减少不必要的计算资源消耗。</li>
<li><strong>量化</strong>:
通过量化技术减少模型大小和计算复杂度，从而加快推理速度。</li>
</ul>
<p><strong>Q: Diffusion 模型中的正向扩散过程如何实现？</strong> A:
正向扩散过程通常通过一系列高斯噪声的添加来实现，每次添加一定强度的噪声，直到原始数据完全被噪声掩盖。这一过程可以视为数据分布的退化。</p>
<p><strong>Q: Diffusion 模型中的逆向扩散过程是如何去噪的？</strong> A:
逆向扩散过程通过训练一个去噪模型来逐步去除噪声，每次迭代都试图预测并移除一定量的噪声，直至恢复出原始数据。</p>
<p><strong>Q: 控制 Diffusion 模型生成结果的方法有哪些？</strong> A:
可以通过条件输入（如类别标签、文本描述等）来控制生成结果，或者通过调整模型参数（如去噪步数、噪声强度等）来微调生成效果。</p>
<p><strong>Q: Diffusion 模型在生成图像时为什么会模糊？</strong> A: 由于
Diffusion
模型需要多次迭代去除噪声，这个过程中累积的小误差可能会导致生成的图像变得模糊不清。</p>
<p><strong>Q: 如何解决 Diffusion 模型生成结果模糊的问题？</strong> A:
可以尝试改进去噪算法，比如引入注意力机制来增强模型的局部感知能力，或者采用后处理技术（如锐化滤波）来增强生成图像的清晰度。</p>
<h2 id="多模态模型">多模态模型</h2>
<ol type="1">
<li>SAM</li>
<li>CLIP</li>
<li>BLIP</li>
<li>HunyuanDiT</li>
</ol>
<h2 id="大语言模型">大语言模型</h2>
<ol type="1">
<li>RAG 工程</li>
<li>Prompt 优化</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-23T15:19:31.000Z" title="2024/9/23 下午11:19:31">2024-09-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-23T15:19:31.000Z" title="2024/9/23 下午11:19:31">2024-09-23</time></span><span class="level-item"><a class="link-muted" href="/categories/interview/">interview</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/23/interview/shenxinfu/">深信服算法面试</a></p><div class="content"><p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/">深度学习书籍</a></p></div><a class="article-more button is-small is-size-7" href="/2024/09/23/interview/shenxinfu/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-19T16:41:25.000Z" title="2024/9/20 上午12:41:25">2024-09-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-19T16:41:25.000Z" title="2024/9/20 上午12:41:25">2024-09-20</time></span><span class="level-item"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/categories/Machine-Learning/Deep-Learning/">Deep Learning</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/20/knowledge/image-process/">图像处理</a></p><div class="content"><p>1.对深度学习相关神经网络理解深入，如 DNN、CNN、RNN、GAN 等；
2.有深厚的理论研究背景和数据基础，熟悉
EM、MCMC、LR、LDA、PCA、时间序列等数学方法；
4.熟悉一种以上的深度学习的开源框架，如
Caffe、TensorFlow、ARMAILibrary、SNPE、OpenGLES 等。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-11T08:42:52.000Z" title="2024/9/11 下午4:42:52">2024-09-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-11T08:42:52.000Z" title="2024/9/11 下午4:42:52">2024-09-11</time></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/11/project/rocm/">AMD GPU MI210 深度学习疑难杂症</a></p><div class="content"><blockquote>
<p><a target="_blank" rel="noopener" href="https://rocm.docs.amd.com/en/develop/what-is-rocm.html">ROCm
官方文档</a></p>
</blockquote>
<h2 id="rocm">ROCm</h2>
<h2 id="pytorch">Pytorch</h2>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/3rd-party/pytorch-install.html">PyTorch
for ROCm 官方文档</a></p>
</blockquote>
<h3 id="方法一使用-docker-镜像-rocmpytorch">方法一：使用 docker 镜像
rocm/pytorch</h3>
<h3 id="方法二pytorch-官方轮子">方法二：Pytorch 官方轮子</h3>
<h2 id="apex">APEX</h2>
<ul>
<li>Pytorch 扩展，用于混合精度与分布式训练的工具</li>
<li><a target="_blank" rel="noopener" href="https://github.com/ROCm/apex">Github</a></li>
</ul>
<h3 id="modulenotfounderror-fused_layer_norm_cuda">ModuleNotFoundError:
fused_layer_norm_cuda</h3>
<p>通过源码安装 APEX 解决，注意 Pytorch 版本对应的源码分支</p>
<ol type="1">
<li>GitHub 拉取相应分支源码</li>
<li><code>cd apex</code></li>
<li>输入命令安装 apex，耗费时间可能较长</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">if</span> pip &gt;= 23.1 (ref: https://pip.pypa.io/en/stable/news/<span class="comment">#v23-1) which supports multiple `--config-settings` with the same key...</span></span></span><br><span class="line">pip install -v --no-build-isolation --config-settings "--build-option=--cpp_ext" --config-settings "--build-option=--cuda_ext" ./</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">otherwise</span></span><br><span class="line">python setup.py install --cpp_ext --cuda_ext</span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-05T15:09:24.000Z" title="2024/9/5 下午11:09:24">2024-09-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:09:24.000Z" title="2024/9/5 下午11:09:24">2024-09-05</time></span><span class="level-item"><a class="link-muted" href="/categories/algorithm/">algorithm</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/05/algorithm/interval/">区间题目集合</a></p><div class="content"><h2 id="leetcode-打气球">leetcode 打气球</h2>
<p>右端点排序，合并区间</p>
<h2 id="美团种树">美团种树</h2>
<p>随着种树数量的增加，树总量单调递增，可以通过二分法查询种树量</p>
<h2 id="美团流星">美团流星</h2>
<p>左端点和右端点分开排序，计算最大经过区间数量</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-09-03T02:33:02.000Z" title="2024/9/3 上午10:33:02">2024-09-03</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-03T02:33:02.000Z" title="2024/9/3 上午10:33:02">2024-09-03</time></span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/03/paper/hunyuan-dit/">Hunyuan-DiT</a></p><div class="content"><ul>
<li><p>Paper: Hunyuan-DiT : A Powerful Multi-Resolution Diffusion
Transformer with Fine-Grained Chinese Understanding</p></li>
<li><p>Authors: Zhimin Li, Jianwei Zhang, Qin Lin, Jiangfeng Xiong,
Yanxin Long, Xinchi Deng, Yingfang Zhang, Xingchao Liu, Minbin Huang,
Zedong Xiao, Dayou Chen, Jiajun He, Jiahao Li, Wenyue Li, Chen Zhang,
Rongwei Quan, Jianxiang Lu, Jiabin Huang, Xiaoyan Yuan, Xiaoxiao Zheng,
Yixuan Li, Jihong Zhang, Chao Zhang, Meng Chen, Jie Liu, Zheng Fang,
Weiyan Wang, Jinbao Xue, Yangyu Tao, Jianchen Zhu, Kai Liu, Sihuan Lin,
Yifu Sun, Yun Li, Dongdong Wang, Mingtao Chen, Zhichao Hu, Xiao Xiao,
Yan Chen, Yuhong Liu, Wei Liu, Di Wang, Yong Yang, Jie Jiang, Qinglin
Lu</p></li>
<li><p>Code &amp; Pretrained Model: <a target="_blank" rel="noopener" href="https://github.com/Tencent/HunyuanDiT">GitHub</a></p></li>
</ul>
<h2 id="背景">背景</h2>
<ul>
<li>现有一些基于 Diffusion 的文生图模型，如 DALL-E、SD 和 Pixart
缺乏对中文提示词的理解，而 AltDiffusion、PAI-Diffusion 和 Taiyi
这一类具有中文理解能力的模型则仍有进步空间</li>
</ul>
<h2 id="基于-dit-的模块改进">基于 DiT 的模块改进</h2>
<figure>
<img src="https://raw.githubusercontent.com/derolol/picgo/main/images20240903155915-hunyuan-dit-2024-09-03.png" alt="Hunyuan-DiT">
<figcaption aria-hidden="true">Hunyuan-DiT</figcaption>
</figure>
<h3 id="图像编码器">图像编码器</h3>
<p>使用预训练 VAE 提取图像编码用于学习数据分布，SDXL 中的 VAE 相比于
SD1.5 中的 VAE 有较大的提升</p>
<h3 id="文本编码器">文本编码器</h3>
<p>使用预训练中英双语 CLIP 模型以及多语种 T5 模型提取文本编码</p>
<h3 id="混元-dit">混元 DiT</h3>
<ul>
<li>按照<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 2222.4 666"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></svg></mjx-container></span>的大小分块</li>
<li>为了提升模型在细粒度文本条件表现，在特征提取模块使用交叉注意力层融合文本特征</li>
<li>Transformer
块包含编码块和解码块，块中包含了自注意力-交叉注意力-FFN</li>
<li>在解码块增加了与编码块之间的跳层链接</li>
<li>训练时使用 v-prediction 的方式具有更好的表现</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/678942992">v-predition
相关资料</a> 在使用 v-prediction 方法时，模型不直接预测噪声
ε，而是预测了一个加权后的量 v，这个量结合了噪声 ε 和原始数据 x
的信息，能在采样步骤较少的情况下提供有效的信号来指导采样过程</p>
</blockquote>
<h3 id="位置编码和多分辨率图像生成">位置编码和多分辨率图像生成</h3>
<figure>
<img src="https://raw.githubusercontent.com/derolol/picgo/main/images20240903154625-hunyuan-dit-2024-09-03.png" alt="两种位置编码可视化">
<figcaption aria-hidden="true">两种位置编码可视化</figcaption>
</figure>
<ul>
<li>使用二维 RoPE 对绝对位置和相对位置进行编码</li>
<li>为了实现多分辨率图像生成，尝试了两种类型的编码
<ul>
<li><strong>Extended Positional
Encoding</strong>，随着宽高的不同，编码结果也会有巨大的差异</li>
<li><strong>Centralized Interpolative Positional
Encoding</strong>，定义边界<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.459ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 645 727"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g></g></g></svg></mjx-container></span>为编码结果变化的范围，且以图像中心为编码
0 点</li>
</ul></li>
</ul>
<h3 id="提升训练稳定性">提升训练稳定性</h3>
<ul>
<li>使用 QK-Norm，在计算 Q、K 和 V 之前增加归一化层</li>
<li>在跳层模块后增加归一化层，从而避免梯度爆炸</li>
<li>使用 FP32 进行训练避免溢出</li>
</ul>
<h2 id="数据流">数据流</h2>
<h3 id="数据收集与筛选">数据收集与筛选</h3>
<h3 id="图像重标注">图像重标注</h3>
<h3 id="多轮对话增强提示">多轮对话增强提示</h3>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-08-30T02:33:21.000Z" title="2024/8/30 上午10:33:21">2024-08-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-08-30T02:33:21.000Z" title="2024/8/30 上午10:33:21">2024-08-30</time></span><span class="level-item"><a class="link-muted" href="/categories/paper/">paper</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/30/paper/DEADiff/">DEADiff</a></p><div class="content"><ul>
<li><p>Paper: DEADiff: An Efficient Stylization Diffusion Model with
Disentangled Representations</p></li>
<li><p>Authors: Tianhao Qi, Shancheng Fang, Yanze Wu, Hongtao Xie,
Jiawei Liu, Lang Chen, Qian He, Yongdong Zhang</p></li>
<li><p>Code &amp; Dataset: <a target="_blank" rel="noopener" href="https://tianhao-qi.github.io/DEADiff">GitHub</a></p></li>
</ul>
<h2 id="研究背景">研究背景</h2>
<ul>
<li>基于扩散模型的文本-图像生成模型（T2I）的发展，一些工作尝试引入参考图像作为生成模型的状态，风格图像就是其中一种</li>
<li>利用T2I的已有工作
<ul>
<li>基于<strong>本文转换</strong>的方法，将风格图像编码为文本嵌入空间的编码，这种图像到文本的模态转换容易导致信息的丢失</li>
<li>针对风格<strong>微调参数</strong>的方法容易导致过拟合，且在现实生产中不具有实用性</li>
<li>通过<strong>图像编码器</strong>提取风格图像特征
<ul>
<li>T2IAdapter-Style 和 IP-Adapter 使用 Transformer 作为图像编码器，以
CLIP 图像嵌入作为输入，并通过 U-Net 交叉注意层利用提取的图像特征</li>
<li>BLIP-Diffusion 通过 Q-Former
将图像嵌入转化为文本嵌入空间，作为扩散模型文本编码器的输入</li>
</ul></li>
</ul></li>
</ul>
<h2 id="研究方法">研究方法</h2>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jiaoyangwm/article/details/130048612">参考资料</a></p>
</blockquote>
<h3 id="querying-transformerq-former">Querying
Transformer（Q-Former）</h3>
<ul>
<li>由 Image Transformer 和 Text Transformer 组成，共享 Self-Attention
层参数</li>
<li>Image Transformer 提取与本文内容最相近的视觉特征
<ul>
<li>输入：图像特征和可学习 Queries</li>
<li>由于共享 Self-Attention 层参数，Queries
可同时与图像特征和文本特征进行交互</li>
</ul></li>
<li>Text Transformer 作为输入文本的编码器和解码器</li>
</ul>
<h3 id="提取风格特征和内容特征">提取风格特征和内容特征</h3>
<p>解耦风格特征与内容特征提取</p>
<figure>
<img src="https://raw.githubusercontent.com/derolol/picgo/main/images20240902154142-DEADiff-2024-09-02.png" alt="DEADiff">
<figcaption aria-hidden="true">DEADiff</figcaption>
</figure>
<ul>
<li><strong>STRE</strong>（Style Representation Extraction）
<ul>
<li>使用<strong>风格相同</strong>的图像作为扩散模型的风格图像和输出目标</li>
<li>CLIP
提取的风格图像特征作为Q-Former输入的图像特征，文本“Style”提取特征作为Q-Former的文本特征，内部做交叉注意力，输出与文本相关的图像特征作为风格特征</li>
</ul></li>
<li><strong>SERE</strong>（Content Representation Extraction）
<ul>
<li>使用<strong>主体相同但风格不同</strong>的图像作为扩散模型的风格图像和输出目标</li>
<li>CLIP
提取的风格图像特征作为Q-Former输入的图像特征，文本“Content”提取特征作为Q-Former的文本特征，内部做交叉注意力，输出与文本相关的图像特征作为内容特征</li>
</ul></li>
</ul>
<h3 id="disentangled-conditioning-mechanismdcm分离条件机制">Disentangled
Conditioning Mechanism（DCM）分离条件机制</h3>
<p>在使用Diffusion模型去噪的过程中，提取的风格特征和语义特征将作为交叉注意力层的状态输入，从而引导模型更有效地<strong>分离</strong>风格特征和语义特征</p>
<p>模型使用Stable Diffusion
v1.5作为文本-图像生成模型，将16个交叉注意力层编号为0-15，其中，4-8层为Coarse层，其余为Fine层</p>
<figure>
<img src="https://raw.githubusercontent.com/derolol/picgo/main/images20240902154039-DEADiff-2024-09-02.png" alt="Disentangled Conditioning Mechanism">
<figcaption aria-hidden="true">Disentangled Conditioning
Mechanism</figcaption>
</figure>
<ul>
<li>输入
<ul>
<li>风格信息将作为高分辨率Fine层的状态输入，使得提取的风格特征更注重笔画、纹理和颜色等细节信息</li>
<li>语义信息将作为低分辨率Coarse层的状态输入</li>
</ul></li>
<li>网络结构 Text-image Crossattention Layer
<ul>
<li>1）计算图像特征<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 760 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>的Key和Value</li>
<li>2）固定参数计算文本特征<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.719ex" height="1.357ex" role="img" focusable="false" viewBox="0 -442 760 599.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>的Key和Value</li>
<li>3）计算Query</li>
<li>4）分别拼接图像和文本的Key以及图像和文本的Value</li>
<li>5）计算交叉注意力</li>
</ul></li>
</ul>
<h2 id="构建成对数据">构建成对数据</h2>
<p>准备主体词列表和风格词列表，组合得到相同主体或相同风格的提示词对，利用Text-to-images模型生成图像</p>
<ol type="1">
<li>构建文本提示词
<ul>
<li>1）主体词：人物、动物、物体和场景四种类别，12000</li>
<li>2）风格词：艺术风格、艺术家风格、笔触等，650</li>
<li>3）1个主体词对应约14个风格词构成提示词组合，160000</li>
</ul></li>
<li>Midjourney生成图像 1个提示词生成4张分辨率为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.557ex" role="img" focusable="false" viewBox="0 -666 4222.4 688"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path></g></g></g></svg></mjx-container></span>的图像，上采样到<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="11.815ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 5222.4 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1500,0)"></path></g><g data-mml-node="mo" transform="translate(2222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(3222.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1000,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1500,0)"></path></g></g></g></svg></mjx-container></span>后，构建文本-图像对，1060000</li>
<li>成对图像选择
<ul>
<li>1）风格特征学习：随机选择相同提示词生成的图像构成图像对</li>
<li>2）内容特征学习：随机选择主体词相同但风格不同的提示词对应的图像对</li>
</ul></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-08-23T10:15:42.000Z" title="2024/8/23 下午6:15:42">2024-08-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-08-23T10:15:42.000Z" title="2024/8/23 下午6:15:42">2024-08-23</time></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/23/algorithm/sort/">排序算法总结</a></p><div class="content"><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zxzxzx0119/article/details/79826380">参考资料</a></p>
</blockquote>
<table style="width:100%;">
<colgroup>
<col style="width: 19%">
<col style="width: 26%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 19%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>排序方法</th>
<th>平均情况</th>
<th>最好情况</th>
<th>最坏情况</th>
<th>空间</th>
<th>稳定性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>冒泡</td>
<td>O(n^2)</td>
<td>O(n)</td>
<td>O(n^2)</td>
<td>O(1)</td>
<td>稳定</td>
</tr>
<tr class="even">
<td>简单选择排序</td>
<td>O(n^2)</td>
<td>O(n^2)</td>
<td>O(n^2)</td>
<td>O(1)</td>
<td>不稳定</td>
</tr>
<tr class="odd">
<td>直接插入排序</td>
<td>O(n^2)</td>
<td>O(n)</td>
<td>O(n^2)</td>
<td>O(1)</td>
<td>稳定</td>
</tr>
<tr class="even">
<td>希尔排序</td>
<td>O(nlogn) ~ O(n^2)</td>
<td>O(n1.3)</td>
<td>O(n^2)</td>
<td>O(1)</td>
<td>不稳定</td>
</tr>
<tr class="odd">
<td>快速排序</td>
<td>O(nlogn)</td>
<td>O(nlogn)</td>
<td>O(n^2)</td>
<td>O(logn)~O(n)</td>
<td>不稳定</td>
</tr>
<tr class="even">
<td>堆排序</td>
<td>O(nlogn)</td>
<td>O(nlogn)</td>
<td>O(nlogn)</td>
<td>O(1)</td>
<td>不稳定</td>
</tr>
<tr class="odd">
<td>归并排序</td>
<td>O(nlogn)</td>
<td>O(nlogn)</td>
<td>O(nlogn)</td>
<td>O(n)</td>
<td>稳定</td>
</tr>
</tbody>
</table>
<ul>
<li>冒泡排序：两层循环，外循环确定起始比较位置，内循环不断移动，与后一位比较判断是否交换</li>
<li>选择排序：两层循环，外循环控制选择次数，内循环遍历取得最值</li>
<li>插入排序：两层循环，外循环控制选择插入的对象，内循环向前遍历插入位置</li>
<li>希尔排序：不断迭代缩小步距的插入排序，通过大步距减少插入排序中向前遍历的次数</li>
<li>快速排序：确定序列中的关键值，根据关键值大小划分序列，子序列继续快排</li>
<li>归并排序：迭代到两两排序，再逐层合并排序结果</li>
<li>桶排序</li>
<li>基数排序</li>
<li>计数排序</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-08-21T15:37:36.000Z" title="2024/8/21 下午11:37:36">2024-08-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-08-21T15:37:36.000Z" title="2024/8/21 下午11:37:36">2024-08-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Computer-Fundamental/">Computer Fundamental</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/21/knowledge/c++/">C++语言基础知识</a></p><div class="content"><h2 id="stl-容器ai-辅助生成待检错">STL 容器（AI 辅助生成、待检错）</h2>
<h3 id="vector">1. <strong>vector</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;vector&gt;</code></li>
<li><strong>描述</strong>: 动态数组，能够自动调整大小</li>
<li><strong>底层结构</strong>: 数组</li>
<li><strong>插入操作</strong>: <code>emplace_back</code>,
<code>insert</code></li>
<li><strong>访问操作</strong>: <code>front</code>, <code>back</code>,
<code>operator[]</code>, <code>at</code></li>
<li><strong>删除操作</strong>: <code>pop_back</code>,
<code>erase</code></li>
<li><strong>应用场景</strong>:
当需要快速随机访问元素且不需要频繁在中间位置插入或删除元素时</li>
<li><strong>string</strong>，头文件<string>，使用类 vector
的数据结构</string></li>
</ul>
<h3 id="list">2. <strong>list</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;list&gt;</code></li>
<li><strong>描述</strong>: 双向链表</li>
<li><strong>底层结构</strong>: 双向链表</li>
<li><strong>插入操作</strong>: <code>emplace_front</code>,
<code>emplace_back</code>, <code>insert</code></li>
<li><strong>访问操作</strong>: <code>front</code>,
<code>back</code></li>
<li><strong>删除操作</strong>: <code>pop_front</code>,
<code>pop_back</code>, <code>remove</code>, <code>erase</code></li>
<li><strong>应用场景</strong>:
需要频繁地在列表的任意位置进行插入和删除操作时</li>
</ul>
<h3 id="queue">3. <strong>queue</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;queue&gt;</code></li>
<li><strong>描述</strong>: 队列，先进先出(FIFO)的数据结构。</li>
<li><strong>底层结构</strong>: 通常由适配器实现，底层使用其他容器如
<code>deque</code> 或 <code>list</code></li>
<li><strong>插入操作</strong>: <code>push</code></li>
<li><strong>访问操作</strong>: <code>front</code>,
<code>back</code></li>
<li><strong>删除操作</strong>: <code>pop</code></li>
<li><strong>应用场景</strong>: 实现 FIFO 操作逻辑，例如任务调度。</li>
</ul>
<h3 id="priority_queue">4. <strong>priority_queue</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;queue&gt;</code></li>
<li><strong>描述</strong>:
优先级队列，总是弹出具有最高优先级的元素。</li>
<li><strong>底层结构</strong>: 通常由适配器实现，底层使用堆数据结构，如
<code>std::vector</code> 作为基础容器。</li>
<li><strong>插入操作</strong>: <code>push</code></li>
<li><strong>访问操作</strong>: <code>top</code></li>
<li><strong>删除操作</strong>: <code>pop</code></li>
<li><strong>应用场景</strong>: 需要快速获取最高优先级元素的场景。</li>
</ul>
<h3 id="deque-double-ended-queue">5. <strong>deque (double-ended
queue)</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;deque&gt;</code></li>
<li><strong>描述</strong>: 双端队列，可以在两端进行高效插入和删除</li>
<li><strong>底层结构</strong>: 分配的连续内存块组成的数组</li>
<li><strong>插入操作</strong>: <code>emplace_front</code>,
<code>emplace_back</code>, <code>push_front</code>,
<code>push_back</code>, <code>insert</code></li>
<li><strong>访问操作</strong>: <code>front</code>, <code>back</code>,
<code>operator[]</code>, <code>at</code></li>
<li><strong>删除操作</strong>: <code>pop_front</code>,
<code>pop_back</code>, <code>erase</code></li>
<li><strong>应用场景</strong>: 当需要从两端高效地添加或移除元素时</li>
</ul>
<h3 id="stack">6. <strong>stack</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;stack&gt;</code></li>
<li><strong>描述</strong>: 栈，后进先出(LIFO)的数据结构。</li>
<li><strong>底层结构</strong>: 通常由适配器实现，底层使用其他容器如
<code>vector</code> 或 <code>deque</code></li>
<li><strong>插入操作</strong>: <code>push</code></li>
<li><strong>访问操作</strong>: <code>top</code></li>
<li><strong>删除操作</strong>: <code>pop</code></li>
<li><strong>应用场景</strong>: 实现 LIFO 操作逻辑，例如表达式求值。</li>
</ul>
<h3 id="set">7. <strong>set</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;set&gt;</code></li>
<li><strong>描述</strong>: 关联容器，存储唯一键值，自动排序</li>
<li><strong>底层结构</strong>: 平衡二叉树 (通常为红黑树)</li>
<li><strong>插入操作</strong>: <code>emplace</code>,
<code>insert</code></li>
<li><strong>访问操作</strong>: <code>find</code>,
<code>lower_bound</code>, <code>upper_bound</code></li>
<li><strong>删除操作</strong>: <code>erase</code></li>
<li><strong>应用场景</strong>:
当需要维护一个有序集合且不允许重复元素时</li>
</ul>
<h3 id="map">8. <strong>map</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;map&gt;</code></li>
<li><strong>描述</strong>: 关联容器，存储键值对，键值唯一并自动排序</li>
<li><strong>底层结构</strong>: 平衡二叉树 (通常为红黑树)</li>
<li><strong>插入操作</strong>: <code>emplace</code>,
<code>insert</code></li>
<li><strong>访问操作</strong>: <code>find</code>,
<code>lower_bound</code>, <code>upper_bound</code></li>
<li><strong>删除操作</strong>: <code>erase</code></li>
<li><strong>应用场景</strong>:
当需要通过键来高效查找、插入和删除数据时</li>
</ul>
<h3 id="unordered_set">9. <strong>unordered_set</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;unordered_set&gt;</code></li>
<li><strong>描述</strong>: 哈希表实现的容器，存储唯一键值</li>
<li><strong>底层结构</strong>: 哈希表</li>
<li><strong>插入操作</strong>: <code>emplace</code>,
<code>insert</code></li>
<li><strong>访问操作</strong>: <code>find</code>,
<code>count</code></li>
<li><strong>删除操作</strong>: <code>erase</code></li>
<li><strong>应用场景</strong>:
当需要快速查找和插入操作而不关心顺序时</li>
</ul>
<h3 id="unordered_map">10. <strong>unordered_map</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;unordered_map&gt;</code></li>
<li><strong>描述</strong>: 哈希表实现的容器，存储键值对，键值唯一</li>
<li><strong>底层结构</strong>: 哈希表</li>
<li><strong>插入操作</strong>: <code>emplace</code>,
<code>insert</code></li>
<li><strong>访问操作</strong>: <code>find</code>,
<code>count</code></li>
<li><strong>删除操作</strong>: <code>erase</code></li>
<li><strong>应用场景</strong>:
当需要通过键来快速查找数据而不关心顺序时</li>
</ul>
<h3 id="pair">11. <strong>pair</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;utility&gt;</code></li>
<li><strong>描述</strong>: 存储两个元素的简单容器</li>
<li><strong>底层结构</strong>: 两个成员变量</li>
<li><strong>插入操作</strong>: 构造函数初始化</li>
<li><strong>访问操作</strong>: <code>first</code>,
<code>second</code></li>
<li><strong>删除操作</strong>: N/A (不可删除)</li>
<li><strong>应用场景</strong>: 当需要同时处理两个相关数据时</li>
</ul>
<h3 id="bitset">12. <strong>bitset</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;bitset&gt;</code></li>
<li><strong>描述</strong>: 存储位序列</li>
<li><strong>底层结构</strong>: 内部实现细节依赖于实现</li>
<li><strong>插入操作</strong>: 构造函数初始化, <code>set</code></li>
<li><strong>访问操作</strong>: <code>test</code>,
<code>operator[]</code></li>
<li><strong>删除操作</strong>: <code>reset</code></li>
<li><strong>应用场景</strong>:
高效处理位操作，例如用于压缩算法、位图等</li>
</ul>
<h3 id="array">13. <strong>array</strong></h3>
<ul>
<li><strong>头文件</strong>: <code>&lt;array&gt;</code></li>
<li><strong>描述</strong>: 固定大小的数组容器。</li>
<li><strong>底层结构</strong>: 数组</li>
<li><strong>插入操作</strong>: N/A (不支持插入操作)</li>
<li><strong>访问操作</strong>: <code>operator[]</code>, <code>at</code>,
<code>front</code>, <code>back</code></li>
<li><strong>删除操作</strong>: N/A (不支持删除操作)</li>
<li><strong>应用场景</strong>:
当需要固定大小的数组且不需要动态调整大小时。</li>
</ul>
<h2 id="无符号和有符号">无符号和有符号</h2>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">short</span> <span class="type">int</span> i=(<span class="type">unsigned</span> <span class="type">short</span> <span class="type">int</span>)(<span class="number">-1234</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%hu\n"</span>,i);</span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-08-15T16:17:31.000Z" title="2024/8/16 上午12:17:31">2024-08-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-08-15T16:17:31.000Z" title="2024/8/16 上午12:17:31">2024-08-16</time></span><span class="level-item"><a class="link-muted" href="/categories/written-test/">written test</a></span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/16/interview/dajiang/">大疆笔试</a></p><div class="content"><h2 id="基础知识考察">基础知识考察</h2>
<h3 id="题型分析">题型分析</h3>
<ol type="1">
<li>20230806 题型：10 单选 + 10 多选 + 10  判断</li>
<li>2025 题型：一个半小时，20 选择 + 10 多选 + 10 判断</li>
</ol></div><a class="article-more button is-small is-size-7" href="/2024/08/16/interview/dajiang/#more">Read more</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/6/">6</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://raw.githubusercontent.com/derolol/picgo/main/images/avatar.png" alt="Derolol"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Derolol</p><p class="is-size-6 is-block">Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">51</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">9</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">57</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/derolol" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/derolol"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Computer-Fundamental/"><span class="level-start"><span class="level-item">Computer Fundamental</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/Machine-Learning/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/Framework/"><span class="level-start"><span class="level-item">Framework</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/categories/interview/"><span class="level-start"><span class="level-item">interview</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/paper/"><span class="level-start"><span class="level-item">paper</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/written-test/"><span class="level-start"><span class="level-item">written test</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li><li><a class="level is-mobile" href="https://ayyha.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">AyyHA</span></span><span class="level-right"><span class="level-item tag">ayyha.github.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI-Agent/"><span class="tag">AI Agent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CL/"><span class="tag">CL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CVPR2022/"><span class="tag">CVPR2022</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CVPR2023/"><span class="tag">CVPR2023</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Synthesis/"><span class="tag">Data Synthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-enhancement/"><span class="tag">Data enhancement</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Generative-Model/"><span class="tag">Generative Model</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HPC/"><span class="tag">HPC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Image-Process/"><span class="tag">Image Process</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multimodal/"><span class="tag">Multimodal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Prototype/"><span class="tag">Prototype</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python-Lib/"><span class="tag">Python Lib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RAG/"><span class="tag">RAG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic-Segmentation/"><span class="tag">Semantic Segmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ZSL/"><span class="tag">ZSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/computer-network/"><span class="tag">computer network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-structure/"><span class="tag">data structure</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/dataset/"><span class="tag">dataset</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/high-performance-computing/"><span class="tag">high-performance computing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interview/"><span class="tag">interview</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language/"><span class="tag">language</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/leetcode/"><span class="tag">leetcode</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/math/"><span class="tag">math</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/prompt/"><span class="tag">prompt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/tree/"><span class="tag">tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/written-test/"><span class="tag">written test</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"><span class="tag">二分法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%81%E4%B8%9A/"><span class="tag">企业</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"><span class="tag">动态规划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%BA%E9%97%B4/"><span class="tag">区间</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8C%BA%E9%97%B4%E5%90%88%E5%B9%B6/"><span class="tag">区间合并</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"><span class="tag">双指针</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"><span class="tag">哈希表</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A0%86/"><span class="tag">堆</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/"><span class="tag">多模态</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"><span class="tag">字符串</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"><span class="tag">扩散模型</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%92%E5%BA%8F%E8%BE%85%E5%8A%A9/"><span class="tag">排序辅助</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"><span class="tag">操作系统</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6%E6%8E%A8%E7%90%86/"><span class="tag">数学推理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E7%94%9F%E5%9B%BE/"><span class="tag">文生图</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A0%88/"><span class="tag">栈</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A0%91/"><span class="tag">树</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D/"><span class="tag">正则匹配</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"><span class="tag">滑动窗口</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A9%E9%98%B5%E5%A4%84%E7%90%86/"><span class="tag">矩阵处理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%93%BE%E8%A1%A8/"><span class="tag">链表</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"><span class="tag">风格迁移</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-26T02:29:09.000Z">2024-09-26</time></p><p class="title"><a href="/2024/09/26/interview/experience/">面试经验</a></p><p class="categories"><a href="/categories/interview/">interview</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-23T15:19:31.000Z">2024-09-23</time></p><p class="title"><a href="/2024/09/23/interview/shenxinfu/">深信服算法面试</a></p><p class="categories"><a href="/categories/interview/">interview</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-19T16:41:25.000Z">2024-09-20</time></p><p class="title"><a href="/2024/09/20/knowledge/image-process/">图像处理</a></p><p class="categories"><a href="/categories/Machine-Learning/">Machine Learning</a> / <a href="/categories/Machine-Learning/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-11T08:42:52.000Z">2024-09-11</time></p><p class="title"><a href="/2024/09/11/project/rocm/">AMD GPU MI210 深度学习疑难杂症</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-05T15:09:24.000Z">2024-09-05</time></p><p class="title"><a href="/2024/09/05/algorithm/interval/">区间题目集合</a></p><p class="categories"><a href="/categories/algorithm/">algorithm</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://raw.githubusercontent.com/derolol/picgo/main/images/head.png" alt="Derolol Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 derolol</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>